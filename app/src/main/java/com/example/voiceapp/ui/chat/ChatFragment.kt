package com.example.voiceapp.ui.chat

import android.Manifest
import android.content.Intent
import android.content.pm.PackageManager
import android.os.Bundle
import android.speech.RecognizerIntent
import android.speech.SpeechRecognizer
import android.view.LayoutInflater
import android.view.View
import android.view.ViewGroup
import android.widget.Toast
import androidx.activity.result.PickVisualMediaRequest
import androidx.activity.result.contract.ActivityResultContracts
import androidx.core.content.ContextCompat
import androidx.core.view.ViewCompat
import androidx.core.view.WindowInsetsCompat
import androidx.core.view.isVisible
import androidx.core.view.updatePadding
import kotlin.math.max
import androidx.fragment.app.Fragment
import androidx.lifecycle.ViewModelProvider
import androidx.recyclerview.widget.LinearLayoutManager
import com.example.voiceapp.R
import com.example.voiceapp.databinding.FragmentChatBinding
import android.speech.tts.TextToSpeech
import android.util.Base64
import android.util.Log
import android.webkit.MimeTypeMap
import com.example.voiceapp.ui.settings.SettingsFragment
import io.noties.markwon.Markwon
import java.util.Locale

class ChatFragment : Fragment() {

    private var _binding: FragmentChatBinding? = null
    private val binding get() = _binding!!

    private lateinit var chatViewModel: ChatViewModel
    private lateinit var chatAdapter: ChatAdapter
    private lateinit var markwon: Markwon

    private var tts: TextToSpeech? = null
    private var lastMessageCount: Int = 0

    // è¿½åŠ : éŸ³å£°èªè­˜é–¢é€£
    private var speechRecognizer: SpeechRecognizer? = null
    private var isListening: Boolean = false

    private var lastPersonality: String? = null
    private var selectedImage: ImageAttachment? = null

    private val pickImageLauncher = registerForActivityResult(ActivityResultContracts.PickVisualMedia()) { uri ->
        if (uri != null) {
            showImagePreview(uri)
        } else if (isAdded) {
            Toast.makeText(requireContext(), "ç”»åƒãŒé¸æŠã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ", Toast.LENGTH_SHORT).show()
        }
    }

    companion object {
        private const val REQ_RECORD_AUDIO = 1001
        private const val TAG = "ChatFragment"
    }

    override fun onCreateView(
        inflater: LayoutInflater,
        container: ViewGroup?,
        savedInstanceState: Bundle?
    ): View {
    chatViewModel = ViewModelProvider(this, ChatViewModelFactory(requireContext()))[ChatViewModel::class.java]
        _binding = FragmentChatBinding.inflate(inflater, container, false)
        return binding.root
    }

    override fun onViewCreated(view: View, savedInstanceState: Bundle?) {
        super.onViewCreated(view, savedInstanceState)
        markwon = Markwon.create(requireContext())
        setupRecyclerView()
        setupClickListeners()
        setupTextToSpeech()
        setupSpeechRecognizer() // è¿½åŠ 
        setupImagePreview()
        setupInsetsHandling()
        observeViewModel()
        // èµ·å‹•æ™‚ã®æ€§æ ¼ã‚’è¨˜éŒ²
        lastPersonality = com.example.voiceapp.ui.settings.SettingsFragment.getPersonality(requireContext())
    }

    private fun setupRecyclerView() {
        chatAdapter = ChatAdapter(markwon)
        binding.rvMessages.apply {
            adapter = chatAdapter
            layoutManager = LinearLayoutManager(context).apply {
                stackFromEnd = true
            }
        }
    }

    private fun setupClickListeners() {
        binding.btnSend.setOnClickListener {
            val message = binding.etMessage.text.toString().trim()
            if (message.isNotEmpty() || selectedImage != null) {
                val currentPersonality = com.example.voiceapp.ui.settings.SettingsFragment.getPersonality(requireContext())
                if (lastPersonality != null && lastPersonality != currentPersonality && (chatViewModel.messages.value?.isNotEmpty() == true)) {
                    chatViewModel.clearChat()
                    clearSelectedImage()
                    Toast.makeText(requireContext(), "æ€§æ ¼è¨­å®šã‚’åæ˜ ã—ã¾ã—ãŸã€‚æ–°ã—ã„ä¼šè©±ã‚’é–‹å§‹ã—ã¾ã™ã€‚", Toast.LENGTH_SHORT).show()
                }
                val systemPrompt = buildSystemPrompt()
                chatViewModel.sendMessage(message.takeIf { it.isNotEmpty() }, selectedImage, systemPrompt)
                lastPersonality = currentPersonality
                binding.etMessage.setText("")
                clearSelectedImage()
            } else {
                Toast.makeText(requireContext(), "ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¾ãŸã¯ç”»åƒã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", Toast.LENGTH_SHORT).show()
            }
        }
        binding.btnMic.setOnClickListener { onMicClicked() }
        // è¿½åŠ : å…¨æ¶ˆå»
        binding.btnClear.setOnClickListener {
            chatViewModel.clearChat()
            clearSelectedImage()
            Toast.makeText(requireContext(), "ãƒãƒ£ãƒƒãƒˆã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ", Toast.LENGTH_SHORT).show()
        }
        binding.btnAttach.setOnClickListener {
            launchImagePicker()
        }
    }

    private fun setupImagePreview() {
        binding.cardImagePreview.isVisible = false
        binding.btnRemoveImage.setOnClickListener { clearSelectedImage() }
    }

    private fun setupInsetsHandling() {
        val initialRvPaddingBottom = binding.rvMessages.paddingBottom
        val initialInputPaddingBottom = binding.messageInputContainer.paddingBottom

        ViewCompat.setOnApplyWindowInsetsListener(binding.root) { _, insets ->
            val systemBars = insets.getInsets(WindowInsetsCompat.Type.systemBars())
            val imeVisible = insets.isVisible(WindowInsetsCompat.Type.ime())
            val navBarInset = systemBars.bottom
            val imeInsets = insets.getInsets(WindowInsetsCompat.Type.ime())
            val imeExtra = max(0, imeInsets.bottom - navBarInset)
            val bottomInset = if (imeVisible) imeExtra else navBarInset

            binding.rvMessages.updatePadding(bottom = initialRvPaddingBottom + bottomInset)
            binding.messageInputContainer.updatePadding(bottom = initialInputPaddingBottom + bottomInset)

            if (imeVisible) {
                binding.rvMessages.post {
                    if (chatAdapter.itemCount > 0) {
                        binding.rvMessages.scrollToPosition(chatAdapter.itemCount - 1)
                    }
                }
            }

            insets
        }

        ViewCompat.requestApplyInsets(binding.root)
    }

    private fun launchImagePicker() {
        pickImageLauncher.launch(PickVisualMediaRequest(ActivityResultContracts.PickVisualMedia.ImageOnly))
    }

    private fun showImagePreview(uri: android.net.Uri) {
        val attachment = createImageAttachment(uri)
        if (attachment == null) {
            if (isAdded) {
                Toast.makeText(requireContext(), "ç”»åƒã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ", Toast.LENGTH_SHORT).show()
            }
            clearSelectedImage()
            return
        }
        selectedImage = attachment
        binding.cardImagePreview.isVisible = true
        binding.ivImagePreview.setImageURI(uri)
    }

    private fun clearSelectedImage() {
        selectedImage = null
        binding.cardImagePreview.isVisible = false
        binding.ivImagePreview.setImageDrawable(null)
    }

    private fun createImageAttachment(uri: android.net.Uri): ImageAttachment? {
        return try {
            val resolver = requireContext().contentResolver
            val mimeType = resolver.getType(uri).orFallbackMime(uri)
            val bytes = resolver.openInputStream(uri)?.use { it.readBytes() } ?: return null
            val base64 = Base64.encodeToString(bytes, Base64.NO_WRAP)
            val dataUrl = "data:$mimeType;base64,$base64"
            ImageAttachment(uri = uri, dataUrl = dataUrl)
        } catch (e: Exception) {
            Log.e(TAG, "ç”»åƒã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ", e)
            null
        }
    }

    private fun String?.orFallbackMime(uri: android.net.Uri): String {
        if (!this.isNullOrBlank()) return this
        val extension = MimeTypeMap.getFileExtensionFromUrl(uri.toString())
        if (!extension.isNullOrBlank()) {
            MimeTypeMap.getSingleton().getMimeTypeFromExtension(extension.lowercase())?.let { return it }
        }
        return "image/png"
    }

    private fun setupTextToSpeech() {
        tts = TextToSpeech(requireContext()) { status ->
            if (status == TextToSpeech.SUCCESS) {
                val result = tts?.setLanguage(Locale.JAPANESE)
                if (result == TextToSpeech.LANG_MISSING_DATA || result == TextToSpeech.LANG_NOT_SUPPORTED) {
                    Toast.makeText(requireContext(), "éŸ³å£°åˆæˆã§æ—¥æœ¬èªãŒã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“", Toast.LENGTH_SHORT).show()
                }
            } else {
                Toast.makeText(requireContext(), "TTSåˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ", Toast.LENGTH_SHORT).show()
            }
        }
    }

    // è¿½åŠ : éŸ³å£°èªè­˜åˆæœŸåŒ–
    private fun setupSpeechRecognizer() {
        if (!SpeechRecognizer.isRecognitionAvailable(requireContext())) {
            Toast.makeText(requireContext(), "éŸ³å£°èªè­˜ãŒç«¯æœ«ã§åˆ©ç”¨ã§ãã¾ã›ã‚“", Toast.LENGTH_LONG).show()
            binding.btnMic.isEnabled = false
            return
        }
        speechRecognizer = SpeechRecognizer.createSpeechRecognizer(requireContext()).apply {
            setRecognitionListener(object : android.speech.RecognitionListener {
                override fun onReadyForSpeech(params: Bundle?) {
                    binding.btnMic.icon = ContextCompat.getDrawable(requireContext(), android.R.drawable.presence_audio_online)
                }
                override fun onBeginningOfSpeech() {}
                override fun onRmsChanged(rmsdB: Float) {}
                override fun onBufferReceived(buffer: ByteArray?) {}
                override fun onEndOfSpeech() {}
                override fun onError(error: Int) {
                    isListening = false
                    binding.btnMic.icon = ContextCompat.getDrawable(requireContext(), android.R.drawable.ic_btn_speak_now)
                    Toast.makeText(requireContext(), "èªè­˜ã‚¨ãƒ©ãƒ¼: $error", Toast.LENGTH_SHORT).show()
                }
                override fun onResults(results: Bundle?) {
                    isListening = false
                    binding.btnMic.icon = ContextCompat.getDrawable(requireContext(), android.R.drawable.ic_btn_speak_now)
                    val texts = results?.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
                    val recognized = texts?.joinToString(" ") ?: ""
                    if (recognized.isNotBlank()) {
                        binding.etMessage.setText(recognized)
                        binding.etMessage.setSelection(recognized.length)
                    }
                }
                override fun onPartialResults(partialResults: Bundle?) {
                    val texts = partialResults?.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION)
                    val partial = texts?.firstOrNull() ?: return
                    binding.etMessage.setText(partial)
                    binding.etMessage.setSelection(partial.length)
                }
                override fun onEvent(eventType: Int, params: Bundle?) {}
            })
        }
    }

    private fun onMicClicked() {
        if (isListening) {
            stopListening()
            return
        }
        // æ¨©é™ãƒã‚§ãƒƒã‚¯
        if (ContextCompat.checkSelfPermission(requireContext(), Manifest.permission.RECORD_AUDIO) != PackageManager.PERMISSION_GRANTED) {
            requestAudioPermission()
        } else {
            startListening()
        }
    }

    private fun requestAudioPermission() {
        requestPermissions(arrayOf(Manifest.permission.RECORD_AUDIO), REQ_RECORD_AUDIO)
    }

    private fun startListening() {
        val intent = Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH).apply {
            putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL, RecognizerIntent.LANGUAGE_MODEL_FREE_FORM)
            putExtra(RecognizerIntent.EXTRA_LANGUAGE, "ja-JP")
            putExtra(RecognizerIntent.EXTRA_PARTIAL_RESULTS, true)
            putExtra(RecognizerIntent.EXTRA_MAX_RESULTS, 3)
            putExtra(RecognizerIntent.EXTRA_PROMPT, "è©±ã—ã‹ã‘ã¦ãã ã•ã„")
        }
        try {
            speechRecognizer?.startListening(intent)
            isListening = true
            binding.btnMic.icon = ContextCompat.getDrawable(requireContext(), android.R.drawable.presence_audio_away)
        } catch (e: Exception) {
            Toast.makeText(requireContext(), "é–‹å§‹ã§ãã¾ã›ã‚“: ${e.message}", Toast.LENGTH_SHORT).show()
        }
    }

    private fun stopListening() {
        isListening = false
        speechRecognizer?.stopListening()
        binding.btnMic.icon = ContextCompat.getDrawable(requireContext(), android.R.drawable.ic_btn_speak_now)
    }

    // æ¨©é™çµæœ
    override fun onRequestPermissionsResult(requestCode: Int, permissions: Array<out String>, grantResults: IntArray) {
        super.onRequestPermissionsResult(requestCode, permissions, grantResults)
        if (requestCode == REQ_RECORD_AUDIO) {
            if (grantResults.isNotEmpty() && grantResults[0] == PackageManager.PERMISSION_GRANTED) {
                startListening()
            } else {
                Toast.makeText(requireContext(), "ãƒã‚¤ã‚¯æ¨©é™ãŒå¿…è¦ã§ã™", Toast.LENGTH_SHORT).show()
            }
        }
    }

    private fun observeViewModel() {
        chatViewModel.messages.observe(viewLifecycleOwner) { messages ->
            val previousCount = lastMessageCount
            chatAdapter.submitList(messages) {
                if (messages.isNotEmpty()) {
                    binding.rvMessages.scrollToPosition(messages.size - 1)
                }
                if (messages.size > previousCount) {
                    val newMessages = messages.subList(previousCount, messages.size)
                    newMessages.filter { !it.isUser }.forEach { speakOut(it.content) }
                }
                lastMessageCount = messages.size
            }
        }

        chatViewModel.isLoading.observe(viewLifecycleOwner) { isLoading ->
            binding.tvGenerating.isVisible = isLoading
            binding.btnSend.isEnabled = !isLoading
            binding.btnAttach.isEnabled = !isLoading
        }

        chatViewModel.error.observe(viewLifecycleOwner) { error ->
            if (error != null) {
                binding.tvError.text = error
                binding.tvError.visibility = View.VISIBLE
                Toast.makeText(context, error, Toast.LENGTH_LONG).show()
            } else {
                binding.tvError.visibility = View.GONE
            }
        }
    }

    private fun buildSystemPrompt(): String {
        val userName = SettingsFragment.getUserName(requireContext())
        val agentName = SettingsFragment.getAgentName(requireContext())
        return when (SettingsFragment.getPersonality(requireContext())) {
            //ãŠã¡ã‚ƒã‚
            "playful" -> """
                ã‚ãªãŸã¯${agentName}ã€‚${userName}ã¨æ—¥æœ¬èªã§ä¼šè©±ã™ã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
                ãƒ»è‡ªåˆ†ã‚’æŒ‡ã™ã¨ãã¯ä¸€äººç§°ã€Œç§ã€ã‚’ä½¿ã„ã¾ã™ã€‚å¿…è¦ã«å¿œã˜ã¦å†’é ­ã§ã€Œ${agentName}ã§ã™ã€ã¨åä¹—ã£ã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚
                ãƒ»${userName}ã®åå‰ã‚’é©åˆ‡ã«å‘¼ã³ã‹ã‘ã€è¦ªã—ã¿ã‚„ã™ãå¯¾å¿œã—ã¾ã™ã€‚
                ã‚¹ã‚¿ã‚¤ãƒ«: ãŠã¡ã‚ƒã‚ã§è¦ªã—ã¿ã‚„ã™ãã€è»½ã„ãƒ¦ãƒ¼ãƒ¢ã‚¢ã‚„çµµæ–‡å­—ã‚’æ™‚ã€…äº¤ãˆã¾ã™(ä¾‹: ğŸ˜Š, âœ¨ ã‚’1ã¤ç¨‹åº¦)ã€‚
                ãŸã ã—å†—é•·ã«ãªã‚‰ãšã€è¦ç‚¹ã¯ç°¡æ½”ãƒ»æ˜ç­ã«ã€‚å®‰å…¨ã§ä¸å¯§ãªè¡¨ç¾ã‚’å¿ƒæ›ã‘ã¦ãã ã•ã„ã€‚
                ä¾é ¼ãŒã‚ã‚Œã°è©³ã—ãã€ç„¡ã‘ã‚Œã°ç°¡æ½”ã«ç­”ãˆã¾ã™ã€‚
                è¿”ç­”ã¯ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã§è¡Œã£ã¦ãã ã•ã„ã€‚
            """.trimIndent()
            //å®¢è¦³çš„
            "objective" -> """
                ã‚ãªãŸã¯${agentName}ã€‚${userName}ã¨æ—¥æœ¬èªã§ä¼šè©±ã™ã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
                ãƒ»è‡ªåˆ†ã‚’æŒ‡ã™ã¨ãã¯ä¸€äººç§°ã€Œç§ã€ã‚’ä½¿ã„ã¾ã™ã€‚å¿…è¦ã«å¿œã˜ã¦å†’é ­ã§ã€Œ${agentName}ã§ã™ã€ã¨åä¹—ã£ã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚
                ãƒ»${userName}ã®åå‰ã‚’å¿…è¦ã«å¿œã˜ã¦ç”¨ã„ã€ä¸å¯§ã«å¯¾å¿œã—ã¾ã™ã€‚
                ã‚¹ã‚¿ã‚¤ãƒ«: å®¢è¦³çš„ãƒ»ä¸­ç«‹ãƒ»ç°¡æ½”ã€‚äº‹å®Ÿãƒ™ãƒ¼ã‚¹ã§ä¸è¦ãªæ„Ÿæƒ…è¡¨ç¾ã¯é¿ã‘ã¾ã™ã€‚
                æ ¹æ‹ ãŒæ›–æ˜§ãªå ´åˆã¯æ¨æ¸¬ã¨æ˜ç¤ºã—ã€ä¸ç¢ºå®Ÿæ€§ã‚’ä¼ãˆã¾ã™ã€‚å¿…è¦ã«å¿œã˜ã¦ç®‡æ¡æ›¸ãã‚„æ‰‹é †ã§æ•´ç†ã—ã¾ã™ã€‚
                è¿”ç­”ã¯ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã§è¡Œã£ã¦ãã ã•ã„ã€‚
            """.trimIndent()
            //å„ªã—ã
            else -> """
                ã‚ãªãŸã¯${agentName}ã€‚${userName}ã¨æ—¥æœ¬èªã§ä¼šè©±ã™ã‚‹AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
                ãƒ»è‡ªåˆ†ã‚’æŒ‡ã™ã¨ãã¯ä¸€äººç§°ã€Œç§ã€ã‚’ä½¿ã„ã¾ã™ã€‚å¿…è¦ã«å¿œã˜ã¦å†’é ­ã§ã€Œ${agentName}ã§ã™ã€ã¨åä¹—ã£ã¦ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚
                ãƒ»${userName}ã®æ°—æŒã¡ã«é…æ…®ã—ã€åå‰ã‚’æ·»ãˆãŸä¸å¯§ãªå‘¼ã³ã‹ã‘ã‚’è¡Œã„ã¾ã™ã€‚
                ã‚¹ã‚¿ã‚¤ãƒ«: å„ªã—ãä¸å¯§ã§å…±æ„Ÿçš„ã€‚ç›¸æ‰‹ã®æ„å›³ã‚’ãã¿å–ã‚Šã€å®‰å¿ƒæ„Ÿã®ã‚ã‚‹è¨€ã„å›ã—ã‚’å¿ƒæ›ã‘ã¾ã™ã€‚
                é•·ããªã‚Šéããªã„ã‚ˆã†ã«é…æ…®ã—ã¤ã¤ã€å½¹ç«‹ã¤è£œè¶³ãŒã‚ã‚‹å ´åˆã¯çŸ­ã„ææ¡ˆã‚’æ·»ãˆã¾ã™ã€‚
                è¿”ç­”ã¯ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã§è¡Œã£ã¦ãã ã•ã„ã€‚
            """.trimIndent()
        }
    }

    private fun speakOut(text: String) {
        if (text.isBlank()) return
        tts?.speak(text, TextToSpeech.QUEUE_ADD, null, System.currentTimeMillis().toString())
    }

    override fun onDestroyView() {
        super.onDestroyView()
        tts?.stop()
        tts?.shutdown()
        tts = null
        speechRecognizer?.destroy()
        speechRecognizer = null
        clearSelectedImage()
        _binding = null
    }
}
